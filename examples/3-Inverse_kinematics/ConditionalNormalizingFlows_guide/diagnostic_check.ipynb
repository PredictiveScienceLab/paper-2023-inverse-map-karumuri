{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c4509bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fba7e666678>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.distributions as dist\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as st\n",
    "import math\n",
    "import os\n",
    "import pickle\n",
    "from sklearn.utils import shuffle\n",
    "# get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import arviz as az\n",
    "import pyro\n",
    "import pyro.distributions as dist_pyro\n",
    "from pyro.infer import MCMC, HMC, NUTS\n",
    "import argparse\n",
    "import json\n",
    "\n",
    "pyro.set_rng_seed(37)\n",
    "\n",
    "np.random.seed(120)\n",
    "torch.manual_seed(120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72dda6db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200000 32 64 0.001 15 100 a\n",
      "results_dir\n"
     ]
    }
   ],
   "source": [
    "n_steps=200000\n",
    "num_particles=32\n",
    "n_y=64 \n",
    "lr=1e-3\n",
    "realnvp_architecture=[15,100]\n",
    "job='a'\n",
    "\n",
    "len_flow, num_neurons = realnvp_architecture[0], realnvp_architecture[1]\n",
    "print(n_steps, num_particles, n_y, lr, len_flow, num_neurons, job)\n",
    "print('results_dir')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83f791f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parser=argparse.ArgumentParser()\n",
    "# parser.add_argument('-n_steps', dest='n_steps', type=int, default=100, help='Maximum number of iterations.')\n",
    "# parser.add_argument('-num_particles', dest='num_particles', type=int, default=5, help='Number of particles to consider in each iteration.')\n",
    "# parser.add_argument('-n_y', dest='n_y', type=int, default=32, help='Number of observed data samples to consider in each iteration.')\n",
    "# parser.add_argument('-lr', dest='lr', type=float, default=1e-3, help='Learning rate.')\n",
    "# parser.add_argument('-realnvp_architecture', dest='realnvp_architecture', type=json.loads, default=\"[15, 100]\",  help='RealNVP architecture parametersas list: [Length of flow, Number of neurons].')\n",
    "# parser.add_argument('-job', dest='job', type=str, default='a', help='Model variation currently trying.')\n",
    "# args = parser.parse_args()\n",
    "\n",
    "# # Print all the arguments\n",
    "# for arg in vars(args):\n",
    "#     print(f'{arg}: {getattr(args, arg)}')\n",
    "\n",
    "# n_steps = args.n_steps\n",
    "# num_particles = args.num_particles\n",
    "# n_y = args.n_y\n",
    "# lr = args.lr\n",
    "# len_flow, num_neurons = args.realnvp_architecture[0], args.realnvp_architecture[1]\n",
    "# job = args.job\n",
    "# print(n_steps, num_particles, n_y, lr, len_flow, num_neurons, job)\n",
    "\n",
    "# Specify the directory name\n",
    "results_dir = os.path.join(os.getcwd(), 'results-'+str(job)) \n",
    "# Check if the directory already exists; if not, create it\n",
    "if not os.path.exists(results_dir):\n",
    "    os.makedirs(results_dir)\n",
    "\n",
    "\n",
    "# In[3]:\n",
    "\n",
    "\n",
    "xi_dim = 4 \n",
    "y_dim = 2\n",
    "noise_scale = torch.tensor([0.01, 0.01])\n",
    "lens = torch.tensor([0.5, 0.5, 1.0]) # lengths of the kinematic links\n",
    "prior_scale = torch.tensor([0.25, 0.5, 0.5, 0.5]) # prior scale\n",
    "\n",
    "# Defining prior distribution\n",
    "prior_xi_dist = dist.Normal(loc=torch.zeros(xi_dim), scale=prior_scale)\n",
    "\n",
    "\n",
    "# In[4]:\n",
    "\n",
    "\n",
    "def segment_points(p_, length, angle):\n",
    "    p = torch.zeros(p_.shape)\n",
    "    p[:,0] = p_[:,0] + length * torch.cos(angle)\n",
    "    p[:,1] = p_[:,1] + length * torch.sin(angle)\n",
    "    return p_, p\n",
    "\n",
    "def forward_process(xi): # N x d_xi\n",
    "    \"\"\"\n",
    "    Implements the forward process f(xi) and \n",
    "    and returns each of the armâ€™s end points as dictionary.\n",
    "    \"\"\"\n",
    "    values = dict();\n",
    "    xi = xi.reshape(-1,4)\n",
    "    A = torch.stack([torch.zeros((xi.shape[0])), xi[:, 0]], axis=1)\n",
    "    _, B = segment_points(A, lens[0], xi[:,1])\n",
    "    _, C = segment_points(B, lens[1], xi[:,1] + xi[:,2])\n",
    "    _, D = segment_points(C, lens[2], xi[:,1] + xi[:,2] + xi[:,3])\n",
    "    values['A'] = A\n",
    "    values['B'] = B\n",
    "    values['C'] = C\n",
    "    values['D'] = D\n",
    "    return values;\n",
    "\n",
    "\n",
    "# In[5]:\n",
    "\n",
    "\n",
    "class RealNVP(nn.Module):\n",
    "    def __init__(self, base_dist, split_dim, len_flow, nets, nett, neta, netb, perm):\n",
    "        super(RealNVP, self).__init__()\n",
    "        \n",
    "        self.base_dist = base_dist\n",
    "        self.split_dim = split_dim\n",
    "        self.len_flow = len_flow\n",
    "        self.t = torch.nn.ModuleList([nett() for _ in range(self.len_flow)])\n",
    "        self.s = torch.nn.ModuleList([nets() for _ in range(self.len_flow)])\n",
    "        self.a = torch.nn.ModuleList([neta() for _ in range(self.len_flow)])\n",
    "        self.b = torch.nn.ModuleList([netb() for _ in range(self.len_flow)])\n",
    "        self.perm = perm\n",
    "\n",
    "    # forward transformation z, y --> xi, xi = g(z, y), log_det_J here is new/old\n",
    "    def g(self, z, y):\n",
    "        log_det_J = z.new_zeros(z.shape[0])\n",
    "        xi = z\n",
    "        for i in range(self.len_flow):\n",
    "            u1, u2 = torch.split(xi, split_size_or_sections= [self.split_dim, z.shape[1]-self.split_dim], dim=-1)\n",
    "            v1 = ( u1 * torch.exp(self.s[i]( torch.cat((u2, y), dim=1) )) ) + self.t[i]( torch.cat((u2, y), dim=1) )\n",
    "            v2 = ( u2 * torch.exp(self.a[i]( torch.cat((v1, y), dim=1) )) ) + self.b[i]( torch.cat((v1, y), dim=1) )\n",
    "            log_det_J +=  self.s[i]( torch.cat((u2, y), dim=1) ).sum(-1) + self.a[i]( torch.cat((v1, y), dim=1) ).sum(-1) \n",
    "            xi = torch.cat((v1, v2), dim=-1)\n",
    "            if i < self.len_flow-1:\n",
    "                xi = torch.matmul(xi, self.perm[i])   \n",
    "        return xi, log_det_J\n",
    "        \n",
    "    def sample(self, z, y): \n",
    "        xi = self.g(z, y)[0]\n",
    "        return xi\n",
    "\n",
    "\n",
    "# In[6]:\n",
    "\n",
    "class AVI(nn.Module):\n",
    "    def __init__(self, xi_dim=4, y_dim=2, f=forward_process, noise_scale=0.01):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.xi_dim = xi_dim\n",
    "        self.y_dim = y_dim\n",
    "        self.f = f\n",
    "        self.noise_scale = noise_scale\n",
    "        \n",
    "        self.input_dim = xi_dim\n",
    "        self.split_dim = int(xi_dim/2)\n",
    "\n",
    "        self.nets = lambda: nn.Sequential(nn.Linear(self.input_dim-self.split_dim+self.y_dim, num_neurons), nn.LeakyReLU(), nn.Linear(num_neurons, num_neurons), nn.LeakyReLU(), nn.Linear(num_neurons, self.split_dim), nn.Tanh())\n",
    "        self.nett = lambda:  nn.Sequential(nn.Linear(self.input_dim-self.split_dim+self.y_dim, num_neurons), nn.LeakyReLU(), nn.Linear(num_neurons, num_neurons), nn.LeakyReLU(), nn.Linear(num_neurons, self.split_dim))\n",
    "\n",
    "        self.neta = lambda: nn.Sequential(nn.Linear(self.split_dim+self.y_dim, num_neurons), nn.LeakyReLU(), nn.Linear(num_neurons, num_neurons), nn.LeakyReLU(), nn.Linear(num_neurons, self.input_dim-self.split_dim), nn.Tanh())\n",
    "        self.netb = lambda: nn.Sequential(nn.Linear(self.split_dim+self.y_dim, num_neurons), nn.LeakyReLU(), nn.Linear(num_neurons, num_neurons), nn.LeakyReLU(), nn.Linear(num_neurons, self.input_dim-self.split_dim))\n",
    "\n",
    "        self.len_flow = len_flow\n",
    "\n",
    "        self.base_dist = dist.MultivariateNormal(torch.zeros(self.input_dim), torch.eye(self.input_dim))\n",
    "        \n",
    "        perm_file_path = os.path.join(results_dir, 'perm.pkl')\n",
    "        if os.path.exists(perm_file_path):\n",
    "            with open(perm_file_path, 'rb') as file:\n",
    "                self.perm = pickle.load(file)\n",
    "        else:\n",
    "            self.perm = []\n",
    "            arr =  torch.eye(self.input_dim)\n",
    "            for i in range(self.len_flow-1):\n",
    "                self.perm.append(shuffle(arr)) #random_state=i\n",
    "            with open(perm_file_path, 'wb') as file:\n",
    "                pickle.dump(self.perm, file)\n",
    "\n",
    "        self.model = RealNVP(self.base_dist, self.split_dim, self.len_flow, self.nets, self.nett, self.neta, self.netb, self.perm)\n",
    "    \n",
    "    def observed_data(self, n=30):\n",
    "        xi_data = dist.Normal(loc=torch.zeros(self.xi_dim), scale=prior_scale).sample([n])\n",
    "        y_data = self.f(xi_data)['D'] + self.noise_scale * torch.randn(*self.f(xi_data)['D'].shape)\n",
    "        return xi_data, y_data\n",
    "    \n",
    "    def log_joint(self, xi, y): # xi is z_k\n",
    "        \n",
    "        log_prior = dist.Normal(loc=torch.zeros(self.xi_dim), scale=prior_scale).log_prob(xi).sum(axis=1)\n",
    "        log_likelihood = dist.Normal(loc=self.f(xi)['D'], scale=self.noise_scale).log_prob(y).sum(axis=1)\n",
    "        log_joint = log_prior + log_likelihood\n",
    "\n",
    "        return log_joint\n",
    "    \n",
    "    def forward(self, num_particles=2):\n",
    "        np.random.seed(120)\n",
    "        torch.manual_seed(120)\n",
    "        \n",
    "        _, y = self.observed_data(n=n_y)\n",
    "        \n",
    "        loss = 0\n",
    "        for i in range(y.shape[0]):\n",
    "            \n",
    "            y_samples = y[i,:].repeat(num_particles, 1)\n",
    "            z_samples = torch.autograd.Variable( self.base_dist.sample((num_particles, )) )\n",
    "            z_k, log_det_J = self.model.g(z_samples, y_samples)\n",
    "            loss_ = (- self.log_joint(z_k, y[i,:]) + self.base_dist.log_prob(z_samples) - log_det_J).mean()\n",
    "            #or\n",
    "            #loss_ = (- self.log_joint(z_k, y[i,:]) - log_det_J).mean()\n",
    "            loss += loss_\n",
    "    \n",
    "        return loss/y.shape[0]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fa28704c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: gradient_norm = 2012918.125, lr = 0.00100\n",
      "step 10000: gradient_norm = 1804.737, lr = 0.00100\n",
      "step 20000: gradient_norm = 1563.761, lr = 0.00100\n",
      "step 30000: gradient_norm = 1886.712, lr = 0.00100\n",
      "step 40000: gradient_norm = 1668.728, lr = 0.00100\n",
      "step 50000: gradient_norm = 2907.569, lr = 0.00100\n",
      "step 60000: gradient_norm = 1347.585, lr = 0.00100\n",
      "step 70000: gradient_norm = 1335.664, lr = 0.00100\n",
      "step 80000: gradient_norm = 2287.469, lr = 0.00100\n",
      "step 90000: gradient_norm = 3953.543, lr = 0.00100\n",
      "step 100000: gradient_norm = 1451.791, lr = 0.00100\n",
      "step 110000: gradient_norm = 936.846, lr = 0.00100\n",
      "step 120000: gradient_norm = 1227.711, lr = 0.00100\n",
      "step 130000: gradient_norm = 772.581, lr = 0.00100\n",
      "step 140000: gradient_norm = 947.432, lr = 0.00100\n",
      "step 150000: gradient_norm = 892.338, lr = 0.00100\n",
      "step 160000: gradient_norm = 787.948, lr = 0.00100\n",
      "step 170000: gradient_norm = 1898.743, lr = 0.00100\n",
      "step 180000: gradient_norm = 1473.167, lr = 0.00100\n",
      "step 190000: gradient_norm = 267.408, lr = 0.00100\n",
      "step 199999: gradient_norm = 785.139, lr = 0.00100\n"
     ]
    }
   ],
   "source": [
    "steps, gradient_norms, learning_rates = [], [], []\n",
    "\n",
    "for step in range(n_steps):\n",
    "    if (step % 10000 == 0) or (step == n_steps - 1):\n",
    "        m = AVI(xi_dim=xi_dim, y_dim=y_dim, f=forward_process, noise_scale=noise_scale)\n",
    "        checkpoint_loaded = torch.load(os.path.join(results_dir,'checkpoint_{}.pt'.format(step)))\n",
    "\n",
    "        step = checkpoint_loaded ['step']\n",
    "        optimizer_state_dict = checkpoint_loaded['optimizer_state_dict']  \n",
    "        model_state_dict = checkpoint_loaded['model_state_dict']  \n",
    "        # print(step)\n",
    "        # print(optimizer_state_dict)\n",
    "        # print(model_state_dict )\n",
    "        m.load_state_dict(model_state_dict)\n",
    "        \n",
    "        loss = m(num_particles=num_particles)\n",
    "        loss.backward()\n",
    "        \n",
    "        # Get the model parameters\n",
    "        parameters = [p for p in m.model.parameters() if p.requires_grad==True]\n",
    "\n",
    "        # Compute the gradient norm\n",
    "        gradient_norm = 0.0\n",
    "        for param in parameters:\n",
    "            if param.grad is not None:\n",
    "                gradient_norm += param.grad.norm()\n",
    "\n",
    "        \n",
    "        print('step %s:' % step, 'gradient_norm = %.3f,' % gradient_norm,  'lr = %.5f' % optimizer_state_dict['param_groups'][0]['lr'])\n",
    "        steps.append(step)\n",
    "        gradient_norms.append(gradient_norm.item())\n",
    "        learning_rates.append(optimizer_state_dict['param_groups'][0]['lr'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b3706e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fba85c2e940>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAERCAYAAABowZDXAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAhf0lEQVR4nO3de5xV5X3v8c9XREAlgkKschFs0cQEAzL1EtFKT+WSVIjWHCCeBpO0RKO2qdGeUPOKt5zTVE49aU9slUaKJoi5SJQkErANCfUWGQRBtAixVGewAUGJKMjF3/ljrcHNOJdnLmvvPcP3/Xrt1+z1rOdZ67fXntm/Wet59noUEZiZmbXmsEoHYGZmXYMThpmZJXHCMDOzJE4YZmaWxAnDzMySOGGYmVmSbpcwJM2VtEXSs4n1/7uk5yStk3Rf0fGZmXVV6m7fw5B0PrATuDciPtxK3RHA94Dfj4jXJL0/IraUI04zs66m251hRMRyYHtpmaTflvRTSSsl/ZukD+Sr/hS4IyJey9s6WZiZNaPbJYxmzAGuiYgxwHXAP+TlpwCnSHpM0pOSJlYsQjOzKnd4pQMomqSjgY8C35fUUNwr/3k4MAK4ABgMLJc0MiJeL3OYZmZVr9snDLKzqNcjYlQT6+qAX0bEXuA/JL1AlkBWlDE+M7MuodtfkoqI35Alg08CKPORfPWDZGcXSBpAdonqxQqEaWZW9bpdwpC0AHgCOFVSnaTPAZcBn5P0DLAOmJJXXwJsk/QcsAy4PiK2VSJuM7Nq1+2G1ZqZWTG63RmGmZkVo1t1eg8YMCCGDRtW6TDMzLqMlStXvhoRA1PqdquEMWzYMGpraysdhplZlyHpP1Pr+pKUmZklccIwM7MkThhmZpakW/VhmFn57d27l7q6Onbv3l3pUKwFvXv3ZvDgwfTs2bPd23DCMLMOqauro2/fvgwbNoyS+7VZFYkItm3bRl1dHcOHD2/3dg75hPHgqnpmL1nP5td3cWK/Plw/4VQ+MXpQpcMy6zJ2797tZFHlJHHcccexdevWDm2nsD4MSUMkLSuZze7Pm6gjSX8vaaOkNZLOKFk3Q9KG/DGjiBgfXFXPrIVrqX99FwHUv76LWQvX8uCq+iJ2Z9ZtOVlUv854j4rs9N4HfCkiTgPOBq6SdFqjOpPI7g47ApgJ/COApGOBG4GzgDOBGyX17+wAZy9Zz669+w8q27V3P7OXrO/sXZmZdXmFJYyIeCUins6fvwE8DzS+1jOFbCrViIgngX6STgAmAI9ExPZ8NrxHgE6f3Gjz67vaVG5mh4Zhw4bx6quvAvDRj3603duZN28emzdv7qywKq4sw2olDQNGA79stGoQ8HLJcl1e1lx5pzqxX582lZtZ17Vv3752tXv88cfbvc+iEkZ7X0tHFd7pnc949wDwxXxuis7e/kyyy1kMHTq0TW2vn3AqsxauPeiyVJ+ePbh+wqmdGqOZvauIgSa33nor3/nOdxg4cCBDhgxhzJgxXHfddVxwwQWMGjWKRx99lOnTp3PKKafwta99jT179nDccccxf/58jj/+eLZt28b06dOpr6/nnHPOofQu3kcffTQ7d+4EYPbs2Xzve9/j7bff5uKLL+bmm29m06ZNTJo0ibFjx/L4448zaNAgHnroIX7yk59QW1vLZZddRp8+fXjiiSfo0+fdf0YvuOACzjrrLJYtW8brr7/O3XffzXnnncfu3bu58sorqa2t5fDDD+f2229n3LhxzJs3j4ULF7Jz507279/PZz7zGR588EHefPNNNmzYwHXXXceePXv49re/Ta9evXj44Yc59thjO3RcGyv0DENST7JkMT8iFjZRpR4YUrI8OC9rrvw9ImJORNRERM3AgUn3zzrgE6MH8deXjGRQvz4IGNSvD399yUiPkjIrSBEDTVasWMEDDzzAM888w+LFi99zP7k9e/ZQW1vLl770JcaOHcuTTz7JqlWrmDZtGrfddhsAN998M2PHjmXdunVcfPHFvPTSS+/Zz9KlS9mwYQNPPfUUq1evZuXKlSxfvhyADRs2cNVVV7Fu3Tr69evHAw88wKWXXkpNTQ3z589n9erVByWLBvv27eOpp57iG9/4BjfffDMAd9xxB5JYu3YtCxYsYMaMGQe+4/L000/zgx/8gF/84hcAPPvssyxcuJAVK1Zwww03cOSRR7Jq1SrOOecc7r333nYf0+YUdoahrEv+buD5iLi9mWqLgKsl3U/Wwb0jIl6RtAT43yUd3eOBWUXE+YnRg5wgzMqkpYEm7f07fOyxx5gyZQq9e/emd+/eXHTRRQetnzp16oHndXV1TJ06lVdeeYU9e/Yc+E7C8uXLWbgw+5/24x//OP37v3eMzdKlS1m6dCmjR48GYOfOnWzYsIGhQ4cyfPhwRo0aBcCYMWPYtGlTUuyXXHLJe9o8+uijXHPNNQB84AMf4KSTTuKFF14A4MILLzzorGHcuHH07duXvn37cswxxxx47SNHjmTNmjVJMbRFkZekzgX+GFgraXVe9lfAUICIuBN4GPgYsBF4C/hMvm67pFt5d27tWyJie4GxmlkZVGKgyVFHHXXg+TXXXMO1117L5MmT+fnPf85NN92UvJ2IYNasWXz+858/qHzTpk306tXrwHKPHj3YtSvt9TS069GjR1K/ROlrKW0PcNhhhx1YPuywwwrp5yhylNSjEaGIOD0iRuWPhyPizjxZkI+OuioifjsiRkZEbUn7uRHxO/njn4uK08zKp4iBJueeey4/+tGP2L17Nzt37uTHP/5xs3V37NjBoEHZmcw999xzoPz888/nvvvuA2Dx4sW89tpr72k7YcIE5s6de6A/o76+ni1btrQYW9++fXnjjTfa9HrOO+885s+fD8ALL7zASy+9xKmnVke/qm8+aGZlc/2EU+nTs8dBZR0daPK7v/u7TJ48mdNPP51JkyYxcuRIjjnmmCbr3nTTTXzyk59kzJgxDBgw4ED5jTfeyPLly/nQhz7EwoULmxxAM378eD71qU9xzjnnMHLkSC699NJWk8Hll1/OFVdcwahRo5LPOr7whS/wzjvvMHLkSKZOncq8efMOOpOopG41p3dNTU14AiWz8nr++ef54Ac/mFy/iFFSO3fu5Oijj+att97i/PPPZ86cOZxxxhmtNzzENPVeSVoZETUp7Q/5e0mZWXkVMdBk5syZPPfcc+zevZsZM2Y4WRTECcPMuryG/gcrlvswzKzDutOl7e6qM94jJwwz65DevXuzbds2J40q1jAfRu/evTu0HV+SMrMOGTx4MHV1dR2ea8GK1TDjXkc4YZhZh/Ts2bNDs7hZ1+FLUmZmlsQJw8zMkjhhmJlZEicMMzNL4oRhZmZJnDDMzCyJE4aZmSVxwjAzsyRFTtE6F/hDYEtEfLiJ9dcDl5XE8UFgYD7b3ibgDWA/sC/11rtmZlacIs8w5gETm1sZEbMbZuIjm6/7F42mYR2Xr3eyMDOrAkVO0bocSJ2HezqwoKhYzMys4yrehyHpSLIzkQdKigNYKmmlpJmttJ8pqVZSrW9+ZmZWnIonDOAi4LFGl6PGRsQZwCTgKknnN9c4IuZERE1E1AwcOLDoWM3MDlnVkDCm0ehyVETU5z+3AD8EzqxAXGZmVqKiCUPSMcDvAQ+VlB0lqW/Dc2A88GxlIjQzswZFDqtdAFwADJBUB9wI9ASIiDvzahcDSyPizZKmxwM/lNQQ330R8dOi4jQzszSFJYyImJ5QZx7Z8NvSsheBjxQTlZmZtVc19GGYmVkX4IRhZmZJnDDMzCyJE4aZmSVxwjAzsyROGGZmlsQJw8zMkjhhmJlZEicMMzNL4oRhZmZJnDDMzCyJE4aZmSVxwjAzsyROGGZmlsQJw8zMkhSWMCTNlbRFUpOz5Um6QNIOSavzx1dL1k2UtF7SRklfLipGMzNLV+QZxjxgYit1/i0iRuWPWwAk9QDuACYBpwHTJZ1WYJxmZpagsIQREcuB7e1oeiawMSJejIg9wP3AlE4NzszM2qzSfRjnSHpG0mJJH8rLBgEvl9Spy8vMzKyCCpvTO8HTwEkRsVPSx4AHgRFt3YikmcBMgKFDh3ZqgGZm9q6KnWFExG8iYmf+/GGgp6QBQD0wpKTq4Lysue3MiYiaiKgZOHBgoTGbmR3KKpYwJP2WJOXPz8xj2QasAEZIGi7pCGAasKhScZqZWaawS1KSFgAXAAMk1QE3Aj0BIuJO4FLgSkn7gF3AtIgIYJ+kq4ElQA9gbkSsKypOMzNLo+wzunuoqamJ2traSodhZtZlSFoZETUpdSs9SsrMzLoIJwwzM0vihGFmZkmcMMzMLIkThpmZJXHCMDOzJE4YZmaWxAnDzMySOGGYmVkSJwwzM0vS6r2kJPUDPg0MK60fEX9WWFRmZlZ1Um4++DDwJLAWeKfYcMzMrFqlJIzeEXFt4ZGYmVlVS+nD+LakP5V0gqRjGx6FR2ZmZlUl5QxjDzAbuAFouBd6ACcXFZSZmVWflITxJeB3IuLVooMxM7PqlXJJaiPwVls3LGmupC2Snm1m/WWS1khaK+lxSR8pWbcpL18tyTMimZlVgZQzjDeB1ZKWAW83FCYMq50HfBO4t5n1/wH8XkS8JmkSMAc4q2T9OJ/VmJlVj5SE8WD+aJOIWC5pWAvrHy9ZfBIY3NZ9mJlZ+bSYMCT1AC6PiHEFx/E5YHHJcgBLJQVwV0TMaSHGmcBMgKFDhxYapJnZoazFhBER+yW9I+mYiNhRRACSxpEljLElxWMjol7S+4FHJP17RCxvJsY5ZJezqKmpiabqmJlZx6VcktoJrJX0CFl/BtA5twaRdDrwLWBSRGwr2XZ9/nOLpB8CZwJNJgwzMyuPlISxMH90KklD8+3+cUS8UFJ+FHBYRLyRPx8P3NLZ+zczs7ZpNWFExD2SjgBOyYvWR8Te1tpJWgBcAAyQVAfcCPTMt3kn8FXgOOAfJAHsi4ga4Hjgh3nZ4cB9EfHTNr4uMzPrZCl3q70AuAfYBAgYImlGc30KDSJieivr/wT4kybKXwQ+8t4WZmZWSSmXpP4WGB8R6wEknQIsAMYUGZiZmVWXlG9692xIFgB5f0PP4kIyM7NqlHKGUSvpW8B38uXLAN+uw8zsEJOSMK4ErgIahtH+G/APhUVkZmZVKWWU1NvA7fnDzMwOUSmjpM4FbgJO4uA5vT0fhpnZISTlktTdwF8AK4H9xYZjZmbVKiVh7IiIxa1XMzOz7iwlYSyTNJvsNh6l82E8XVhUZmZWdVISRsOkRjUlZQH8fueHY2Zm1SpllFTRc2GYmVkXkPJNbzMzMycMMzNL02rCkNQrpczMzLq3lDOMJxLLzMysG2u201vSbwGDgD6SRpPNhQHwPuDIMsRmZmZVpKVRUhOAy4HBHHwfqTeAv0rZuKS5wB8CWyLiw02sF/B3wMeAt4DLG77fIWkG8JW86tci4p6UfZqZWTGaTRj5B/Q9kv4oIh5o5/bnAd8E7m1m/SRgRP44C/hH4CxJx5JN6VpD9p2PlZIWRcRr7YzDzMw6KOWLez+W9ClgGAfffPCW1hpGxHJJw1qoMgW4NyICeFJSP0knkM0F/khEbAeQ9AgwkWymPzMzq4CUhPEQsIPs5oNvt1K3rQYBL5cs1+VlzZW/h6SZwEyAoUOHdnJ4ZmbWICVhDI6IiYVH0k4RMQeYA1BTUxMVDsfMrNtKGVb7uKSRBe2/HhhSsjw4L2uu3MzMKiQlYYwl63ReL2mNpLWS1nTS/hcBn1bmbLJbqb8CLAHGS+ovqT8wPi8zM7MKSbkkNam9G5e0gKwDe4CkOrKRTz0BIuJO4GGyIbUbyYbVfiZft13SrcCKfFO3NHSAm5lZZaTcrfY/JY0FRkTEP0saCBydsvGImN7K+gCuambdXGBuyn7MzKx4KfeSuhH4n8CsvKgn8J0igzIzs+qT0odxMTAZeBMgIjYDfYsMyszMqk9KwtiTXzoKAElHFRuSmZlVo5SE8T1JdwH9JP0p8C/APxUblpmZVZuUTu//I+lC4DfAqcBXI+KRwiMzM7OqkjKsljxBOEmYmR3CWpoP49GIGCvpDfL+i4ZVZCNi31d4dGZmVjVaur352PynR0SZmVmLZxjHttTQ37w2Mzu0tNSHsZLsUpSAocBr+fN+wEvA8KKDMzOz6tHssNqIGB4RJ5MNo70oIgZExHFkU64uLVeAZmZWHVK+h3F2RDzcsBARi4GPFheSmZlVo5RhtZslfYV37x91GbC5uJDMzKwapZxhTAcGAj/MH+/Py8zM7BCS8k3v7cCflyEWMzOrYq0mjHz+i78EPgT0biiPiN9PaDsR+DugB/CtiPh6o/X/FxiXLx4JvD8i+uXr9gNr83UvRcTk1vZnZmbFSenDmA98l2x01BXADGBra40k9QDuAC4E6oAVkhZFxHMNdSLiL0rqXwOMLtnErogYlRCfmZmVQUofxnERcTewNyJ+ERGfBVo9uwDOBDZGxIsRsQe4H5jSQv3pwIKE7ZqZWQWkJIy9+c9XJH1c0migxW+B5wYBL5cs1+Vl7yHpJLIvAv6spLi3pFpJT0r6RHM7kTQzr1e7dWurJz5mZtZOKZekvibpGOBLwP8D3gf8RctN2mwa8IOI2F9SdlJE1Es6GfiZpLUR8avGDSNiDjAHoKamJhqvNzOzztFiwsj7IUZExI+BHbzbQZ2iHhhSsjw4L2vKNOCq0oKIqM9/vijp52T9G+9JGGZmVh4tXpLK/+Nv73cuVgAjJA2XdARZUljUuJKkDwD9gSdKyvpL6pU/HwCcCzzXuK2ZmZVPyiWpxyR9k2yk1JsNhRHxdEuNImKfpKuBJWTDaudGxDpJtwC1EdGQPKYB9+fzhjf4IHCXpHfIktrXS0dXmZlZ+engz+kmKkjLmiiOlO9hlFtNTU3U1tZWOgwzsy5D0sqIqEmpm/JN77b0W5iZWTeV8k3va5so3gGsjIjVnR6RmZlVpZTvYdSQfcN7UP74PDAR+CdJf1lgbGZmVkVSOr0HA2dExE4ASTcCPwHOJ5uV77biwjMzs2qRcobxfuDtkuW9wPERsatRuZmZdWOpNx/8paSH8uWLgPskHYW/G2FmdshIGSV1q6TFZF+eA7giIhrGrl5WWGRmZlZVUs4wyBOEv+BgZnYIS+nDMDMzc8IwM7M0ThhmZpbECcPMzJI4YZiZWRInDDMzS+KEYWZmSZwwzMwsSaEJQ9JESeslbZT05SbWXy5pq6TV+eNPStbNkLQhf8woMk4zM2td0je920NSD+AO4EKgDlghaVETU61+NyKubtT2WOBGslurB7Ayb/taUfGamVnLijzDOBPYGBEvRsQe4H5gSmLbCcAjEbE9TxKPkM3BYWZmFVJkwhgEvFyyXJeXNfZHktZI+oGkIW1si6SZkmol1W7durUz4jYzsyZUutP7R8CwiDid7CzinrZuICLmRERNRNQMHDiw0wM0M7NMkQmjHhhSsjw4LzsgIrZFRMMkTN8CxqS2NTOz8ioyYawARkgaLukIYBqwqLSCpBNKFicDz+fPlwDjJfWX1B8Yn5eZmVmFFDZKKiL2Sbqa7IO+BzA3ItZJugWojYhFwJ9JmgzsA7YDl+dtt0u6lSzpANwSEduLitXMzFqniKh0DJ2mpqYmams9z5OZWSpJKyOiJqVupTu9zcysi3DCMDOzJE4YZmaWxAnDzMySOGGYmVkSJwwzM0vihGFmZkmcMMzMLIkThpmZJXHCMDOzJE4YZmaWxAnDzMySOGGYmVkSJwwzM0vihGFmZkkKTRiSJkpaL2mjpC83sf5aSc9JWiPpXyWdVLJuv6TV+WNR47ZmZlZehc24J6kHcAdwIVAHrJC0KCKeK6m2CqiJiLckXQncBkzN1+2KiFFFxWdmZm1T5BnGmcDGiHgxIvYA9wNTSitExLKIeCtffBIYXGA8ZmbWAUUmjEHAyyXLdXlZcz4HLC5Z7i2pVtKTkj7RXCNJM/N6tVu3bu1QwGZm1rzCLkm1haT/AdQAv1dSfFJE1Es6GfiZpLUR8avGbSNiDjAHsjm9yxKwmdkhqMgzjHpgSMny4LzsIJL+ALgBmBwRbzeUR0R9/vNF4OfA6AJjNTOzVhSZMFYAIyQNl3QEMA04aLSTpNHAXWTJYktJeX9JvfLnA4BzgdLOcjMzK7PCLklFxD5JVwNLgB7A3IhYJ+kWoDYiFgGzgaOB70sCeCkiJgMfBO6S9A5ZUvt6o9FVZmZWZoroPpf9a2pqora2ttJhmJl1GZJWRkRNSl1/09vMzJI4YZiZWRInDDMzS+KEYWZmSZwwzMwsiROGmZklccIwM7MkThhmZpbECcPMzJI4YZiZWRInDDMzS+KEYWZmSZwwzMwsiROGmZklccIwM7MkThhmZpaksBn3ACRNBP6ObMa9b0XE1xut7wXcC4wBtgFTI2JTvm4W8DlgP/BnEbGkyFjb48FV9cxesp7Nr+/ixH59uH7CqXxi9KCqbttV4/Zr9vEqsm1Xjbujr7mtCptxT1IP4AXgQqCObI7v6aVTrUr6AnB6RFwhaRpwcURMlXQasAA4EzgR+BfglIjY39I+yznj3oOr6pm1cC279r4bUp+ePfjrS0a2+oZVqm1XjduvuXxtu2rcfs1ta1uqWmbcOxPYGBEvRsQe4H5gSqM6U4B78uc/AP6bssm9pwD3R8TbEfEfwMZ8e1Vj9pL1B71RALv27mf2kvVV27aS+/Zr7hptK7lvv+bytW2vIhPGIODlkuW6vKzJOhGxD9gBHJfYFgBJMyXVSqrdunVrJ4Xeus2v72pTeTW0reS+/Zq7RttK7tuvuXxt26vLd3pHxJyIqImImoEDB5Ztvyf269Om8mpoW8l9+zV3jbaV3Ldfc/natleRCaMeGFKyPDgva7KOpMOBY8g6v1PaVtT1E06lT88eB5X16dmD6yecWrVtK7lvv+au0baS+/ZrLl/b9ipylNQKYISk4WQf9tOATzWqswiYATwBXAr8LCJC0iLgPkm3k3V6jwCeKjDWNmvoVGrPCIVKte2qcfs1+3gV2barxt3R19wehY2SApD0MeAbZMNq50bE/5J0C1AbEYsk9Qa+DYwGtgPTIuLFvO0NwGeBfcAXI2Jxa/sr5ygpM7PuoC2jpApNGOXmhGFm1jbVMqzWzMy6EScMMzNL4oRhZmZJnDDMzCxJt+r0lrQV+M92Nh8AvNqJ4XQWx9U2jqttHFfbdMe4ToqIpG89d6uE0RGSalNHCpST42obx9U2jqttDvW4fEnKzMySOGGYmVkSJ4x3zal0AM1wXG3juNrGcbXNIR2X+zDMzCyJzzDMzCyJE4aZmaWJiEP6AUwE1pNNA/vlgvYxBFgGPAesA/48L7+J7Nbvq/PHx0razMpjWg9MaC1eYDjwy7z8u8ARibFtAtbm+6/Ny44FHgE25D/75+UC/j7fxxrgjJLtzMjrbwBmlJSPybe/MW+rhJhOLTkmq4HfAF+sxPEC5gJbgGdLygo/Ps3to5W4ZgP/nu/7h0C/vHwYsKvkuN3Z3v239BpbiKvw9w3olS9vzNcPS4jruyUxbQJWV+B4NffZUPHfsSb/Hor4gOwqD7Lbrv8KOBk4AngGOK2A/ZzQ8MYCfYEXgNPyP6Trmqh/Wh5Lr/wP5Fd5rM3GC3yP7PbwAHcCVybGtgkY0KjsNvI/UuDLwN/kzz8GLM5/ac8Gflnyi/di/rN//rzhF/ypvK7ytpPa8R79F3BSJY4XcD5wBgd/0BR+fJrbRytxjQcOz5//TUlcw0rrNdpOm/bf3GtsJa7C3zfgC+Qf7GRz73y3tbgarf9b4KsVOF7NfTZU/Hesydff1g+/7vQAzgGWlCzPAmaVYb8PARe28Id0UBzAkjzWJuPNfxFe5d0Pi4PqtRLLJt6bMNYDJ5T8Qq/Pn98FTG9cD5gO3FVSfldedgLw7yXlB9VLjG888Fj+vCLHi0YfIOU4Ps3to6W4Gq27GJjfUr327L+519jK8Sr8fWtomz8/PK+nluIqKRfwMjCiEser0T4aPhuq4nes8eNQ78MYRPaL0qAuLyuMpGFkE0b9Mi+6WtIaSXMl9W8lrubKjwNej4h9jcpTBLBU0kpJM/Oy4yPilfz5fwHHtzOuQfnzxuVtMQ1YULJc6eMF5Tk+ze0j1WfJ/ptsMFzSKkm/kHReSbxt3X97/2aKft8OtMnX78jrpzgP+HVEbCgpK/vxavTZUJW/Y4d6wigrSUcDD5DNIPgb4B+B3wZGAa+QnRaX29iIOAOYBFwl6fzSlZH9+xEViAtJRwCTge/nRdVwvA5SjuPT1n3ks1XuA+bnRa8AQyNiNHAt2fTH7ytq/02ouvetkekc/E9J2Y9XE58NHdpeW6Xu41BPGPVknU4NBudlnU5ST7JfiPkRsRAgIn4dEfsj4h3gn4AzW4mrufJtQD9Jhzcqb1VE1Oc/t5B1lJ4J/FrSCXncJ5B1FrYnrvr8eePyVJOApyPi13mMFT9euXIcn+b20SJJlwN/CFyWfwgQEW9HxLb8+Uqy/oFT2rn/Nv/NlOl9O9AmX39MXr9Fed1LyDrAG+It6/Fq6rOhHdsry+/YoZ4wVgAjJA3P/5udBizq7J1IEnA38HxE3F5SfkJJtYuBZ/Pni4BpknpJGg6MIOu4ajLe/INhGXBp3n4G2bXQ1uI6SlLfhudk/QXP5vuf0cS2FgGfVuZsYEd+SrsEGC+pf365YTzZteVXgN9IOjs/Bp9OiavEQf/5Vfp4lSjH8WluH82SNBH4S2ByRLxVUj5QUo/8+cn58Xmxnftv7jW2FFc53rfSeC8FftaQMFvxB2TX+A9ctinn8Wrus6Ed2yvL71induZ2xQfZqIMXyP6LuKGgfYwlO91bQ8nQQuDbZMPd1uRv3gklbW7IY1pPycii5uIlG1HyFNnQue8DvRLiOplsBMozZEP6bsjLjwP+lWy43b8Ax+blAu7I970WqCnZ1mfzfW8EPlNSXkP2AfEr4JskDKvN2x1F9h/iMSVlZT9eZAnrFWAv2fXfz5Xj+DS3j1bi2kh2Hbvhd6xh1NAf5e/vauBp4KL27r+l19hCXIW/b0DvfHljvv7k1uLKy+cBVzSqW87j1dxnQ8V/x5p6+NYgZmaW5FC/JGVmZomcMMzMLIkThpmZJXHCMDOzJE4YZmaWxAnDrJNJ+qKkIysdh1ln87Bas04maRPZ+PhXKx2LWWfyGYZZB+Tflv+JpGckPSvpRuBEYJmkZXmd8ZKekPS0pO/n9w1C0iZJt0laK+kpSb9Tyddi1honDLOOmQhsjoiPRMSHgW8Am4FxETFO0gDgK8AfRHaTx1qyG9o12BERI8m+gfuNskZu1kZOGGYdsxa4UNLfSDovInY0Wn822YQ4j0laTXbPnpNK1i8o+XlO0cGadcThrVcxs+ZExAuSziC7/8/XJP1royoCHomI6c1topnnZlXHZxhmHSDpROCtiPgO2ZzaZwBvkE23CfAkcG5D/0Te53FKySamlvx8ojxRm7WPzzDMOmYkMFvSO2R3Qr2S7NLSTyVtzvsxLgcWSOqVt/kK2Z1YAfpLWgO8TXY7d7Oq5WG1ZhXi4bfW1fiSlJmZJfEZhpmZJfEZhpmZJXHCMDOzJE4YZmaWxAnDzMySOGGYmVmS/w+vVDtlQaRw+gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.scatter(steps, gradient_norms, label = 'gradient norm')\n",
    "plt.xlabel('step')\n",
    "plt.ylabel('gradient norm')\n",
    "plt.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
